{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Requests and writing/reading to files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reaching out to Weather History API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pprint\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables, then use os module to retrieve it for usage in API requests\n",
    "load_dotenv()\n",
    "\n",
    "WEATHER_API = os.getenv(\"WEATHER_API\")\n",
    "history_url = \"https://api.weatherapi.com/v1/history.json\"\n",
    "\n",
    "\n",
    "# List comprehension to account for dates to pass to API request parameters, cycle through with idx\n",
    "dates = [f\"2024-{n}-01\" for n in range(2, 13)]\n",
    "idx = 1\n",
    "\n",
    "# Begin looping through dates above, up to 2024-12-01\n",
    "while idx < 11:\n",
    "\n",
    "    # 'w' allows for you to write to a file and creates it if it doesn't exist (overrides, use 'a' for appending to end of file)\n",
    "    # '+' allows us to also read from files\n",
    "    with open(f\"history_api_responses/{dates[idx - 1]} to {dates[idx]}\", \"w+\") as file:\n",
    "\n",
    "        # Parameters to pass in to the request\n",
    "        history_params = {\n",
    "            \"q\": \"91730\",\n",
    "            \"dt\": dates[idx - 1],\n",
    "            \"end_dt\": dates[idx],\n",
    "            \"hour\": 0,\n",
    "            \"key\": WEATHER_API,\n",
    "        }\n",
    "\n",
    "        # Initialize variable to hold GET request response\n",
    "        response_history = requests.get(history_url, params=history_params)\n",
    "\n",
    "        # Write json to file\n",
    "        json.dump(response_history.json(), file, indent=4)\n",
    "\n",
    "        # Start reading from top of file\n",
    "        file.seek(0)\n",
    "        file_read = json.load(file)\n",
    "\n",
    "        # Unpack previous data added to history_data (otherwise it'll be a nested list),\n",
    "        # and do the same for values within file_read this will continually append\n",
    "        # response data as we cycle through dates\n",
    "        history_data = [*history_data, *file_read[\"forecast\"][\"forecastday\"]]\n",
    "\n",
    "        # Increment index of dates array\n",
    "        idx += 1\n",
    "\n",
    "# Use to ensure you're getting the response you expect in a 'prettified' form\n",
    "pprint.pprint(history_data, sort_dicts=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reaching out to Weather Forecast API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize URL & Parameters for request\n",
    "\n",
    "forecast_url = \"https://api.weatherapi.com/v1/forecast.json\"\n",
    "\n",
    "forecast_params = {\n",
    "    \"q\": \"91730\",\n",
    "    \"days\": \"14\",\n",
    "    \"hour\": 0,\n",
    "    \"key\": WEATHER_API,\n",
    "}\n",
    "\n",
    "# Open file with reading and writing capabilities\n",
    "with open(\"forecast_api_responses/14_day_forecast.json\", \"w+\") as file:\n",
    "\n",
    "    # Capture API response\n",
    "    response_forecast = requests.get(forecast_url, params=forecast_params)\n",
    "\n",
    "    # Since this is a JSON response, keep formatting by using json.dump to write to file\n",
    "    json.dump(response_forecast.json(), file, indent=4)\n",
    "\n",
    "    # The writing above leaves file pointer where it left off, so setting .seek(0) allows\n",
    "    # us to point back to the beginning of the file to read it in it's entirety\n",
    "    file.seek(0)\n",
    "    file_read = json.load(file)\n",
    "\n",
    "    # Initialize an array to hold a specific key's values that we're going to use\n",
    "    # Again, we use unpacking so we don't end up with a list nested needlessly\n",
    "    forecast_data = [*file_read[\"forecast\"][\"forecastday\"]]\n",
    "\n",
    "# Check we have what we expect in our variable\n",
    "pprint.pprint(forecast_data, sort_dicts=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame Creation for history and forecast data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History DataFrame:\n",
      "\n",
      "           date  mintemp_f  maxtemp_f  avgtemp_f  maxwind_mph  avgvis_miles  avghumidity  rained\n",
      "0   2024-02-01       44.4       54.0       49.7          8.5           5.0           82       1\n",
      "1   2024-02-02       42.1       52.9       47.9          9.8           6.0           79       1\n",
      "2   2024-02-03       42.8       53.3       47.9          8.9           5.0           71       1\n",
      "3   2024-02-04       47.9       55.5       51.1         12.5           4.0           73       1\n",
      "4   2024-02-05       48.6       51.3       50.1          7.8           4.0           95       1\n",
      "5   2024-02-06       46.7       50.7       48.4          7.4           5.0           93       1\n",
      "6   2024-02-07       44.1       49.5       46.6          9.8           5.0           84       1\n",
      "7   2024-02-08       39.7       49.4       44.8         13.4           6.0           73       1\n",
      "8   2024-02-09       41.4       51.3       46.3          7.4           6.0           72       1\n",
      "9   2024-02-10       38.7       56.1       46.4          8.3           6.0           52       0\n",
      "10  2024-02-11       39.1       60.3       48.2          4.9           6.0           28       0\n",
      "11  2024-02-12       41.4       62.5       50.4          4.7           6.0           32       0\n",
      "12  2024-02-13       43.1       62.6       51.6          7.8           6.0           37       0\n",
      "\n",
      "\n",
      "\n",
      "Forecast DataFrame:\n",
      "\n",
      "           date  mintemp_f  maxtemp_f  avgtemp_f  maxwind_mph  avgvis_miles  avghumidity  rain_prediction\n",
      "0   2025-01-20       39.4       61.2       50.0         21.3           6.0           37                0\n",
      "1   2025-01-21       39.0       64.0       48.9          7.6           6.0            8                0\n",
      "2   2025-01-22       46.0       71.2       56.5          6.3           6.0            6                0\n",
      "3   2025-01-23       49.6       75.7       59.2          8.7           6.0            9                0\n",
      "4   2025-01-24       47.4       70.6       57.1          8.1           6.0           12                0\n",
      "5   2025-01-25       44.2       49.6       47.7         16.1           6.0           68                1\n",
      "6   2025-01-26       39.7       45.2       42.2         12.1           5.0           72                1\n",
      "7   2025-01-27       31.8       49.8       40.6          4.3           6.0           53                0\n",
      "8   2025-01-28       32.0       54.2       42.3         14.8           6.0           26                0\n",
      "9   2025-01-29       34.8       61.3       46.5          6.0           6.0           16                0\n",
      "10  2025-01-30       38.8       62.0       49.5          5.1           6.0           25                0\n",
      "11  2025-01-31       40.9       67.4       52.6          4.5           6.0           30                0\n",
      "12  2025-02-01       45.7       73.3       57.1          5.4           6.0           20                0\n",
      "13  2025-02-02       50.2       77.8       61.4          9.4           6.0           20                0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "pd.options.display.width = 1000\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "# We initalize empty lists to append the data we extract from our API responses, to then turn into DataFrames,\n",
    "# as this is the optimal way to create DataFrames, dynamically adding rows will drive up our time complexity,\n",
    "# so we make the tradeoff and double our space complexity because for every row added to the DataFrame dynamically,\n",
    "# every row is recreated in memory; we don't get to enjoy an 0(1) amortized time complexity like with a list (dynamic array)\n",
    "list_history = []\n",
    "list_forecast = []\n",
    "\n",
    "# Using itertools to loop over both lists that carry our response data rather than splitting it into 2 different for loops,\n",
    "# since i know the history will always be longer than our 14 day forecast, i include the if statement inside to check against\n",
    "# our fill value so we don't append empty values\n",
    "for history, forecast in itertools.zip_longest(history_data, forecast_data, fillvalue=None):\n",
    "\n",
    "    history_info = {\n",
    "        \"date\": history[\"date\"],\n",
    "        \"mintemp_f\": history[\"day\"][\"mintemp_f\"],\n",
    "        \"maxtemp_f\": history[\"day\"][\"maxtemp_f\"],\n",
    "        \"avgtemp_f\": history[\"day\"][\"avgtemp_f\"],\n",
    "        \"maxwind_mph\": history[\"day\"][\"maxwind_mph\"],\n",
    "        \"avgvis_miles\": history[\"day\"][\"avgvis_miles\"],\n",
    "        \"avghumidity\": history[\"day\"][\"avghumidity\"],\n",
    "        \"rained\": history[\"day\"][\"daily_will_it_rain\"],\n",
    "    }\n",
    "\n",
    "    list_history.append(history_info)\n",
    "\n",
    "    if forecast != None:\n",
    "    \n",
    "        forecast_info = {\n",
    "            \"date\": forecast[\"date\"],\n",
    "            \"mintemp_f\": forecast[\"day\"][\"mintemp_f\"],\n",
    "            \"maxtemp_f\": forecast[\"day\"][\"maxtemp_f\"],\n",
    "            \"avgtemp_f\": forecast[\"day\"][\"avgtemp_f\"],\n",
    "            \"maxwind_mph\": forecast[\"day\"][\"maxwind_mph\"],\n",
    "            \"avgvis_miles\": forecast[\"day\"][\"avgvis_miles\"],\n",
    "            \"avghumidity\": forecast[\"day\"][\"avghumidity\"],\n",
    "            \"rain_prediction\": forecast[\"day\"][\"daily_will_it_rain\"],\n",
    "        }\n",
    "\n",
    "        list_forecast.append(forecast_info)\n",
    "\n",
    "\n",
    "# Converting lists to DataFrames\n",
    "df_history = pd.DataFrame(list_history)\n",
    "df_forecast = pd.DataFrame(list_forecast)\n",
    "\n",
    "# Output DataFrames content\n",
    "print(\"History DataFrame:\\n\\n\", df_history.iloc[0:13], end='\\n\\n\\n\\n')\n",
    "print(\"Forecast DataFrame:\\n\\n\",df_forecast)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the types of data held within our columns\n",
    "# pprint.pprint(df_forecast.dtypes)\n",
    "# pprint.pprint(df_history.dtypes)\n",
    "\n",
    "# Turning our 'Date' values into type of datetime\n",
    "df_history['date'] = pd.to_datetime(df_history[\"date\"])\n",
    "df_forecast['date'] = pd.to_datetime(df_forecast[\"date\"])\n",
    "\n",
    "# Print to confirm change in column\n",
    "# pprint.pprint(df_history.dtypes)\n",
    "# pprint.pprint(df_forecast.dtypes)\n",
    "\n",
    "# df_history.describe()\n",
    "# df_forecast.describe()\n",
    "# df_history.info()\n",
    "# df_forecast.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and getting data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Separate history dataframe values to input and response variables (x,y)\n",
    "x = df_history[['mintemp_f', 'maxtemp_f', 'avgtemp_f', 'maxwind_mph', 'avghumidity']].values\n",
    "y = df_history[['rained']].values\n",
    "\n",
    "# Separate forecast dataframe values similar to how we did above \n",
    "x_forecast = df_forecast[['mintemp_f', 'maxtemp_f', 'avgtemp_f', 'maxwind_mph', 'avghumidity']].values\n",
    "y_forecast = df_forecast[['rain_prediction']]\n",
    "\n",
    "# Split data between training (70%) and testing (30%) using the historical dataframe values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.18%\n"
     ]
    }
   ],
   "source": [
    "# Initializing model and using a data point's 3 nearest neighbors for classification\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the model with the x (independent/input) & y (dependent/response) training datasets\n",
    "knn.fit(x_train, y_train.ravel())\n",
    "\n",
    "# Outputs the predictions (y) using the x (independent/input) test data\n",
    "y_predictions = knn.predict(x_test)\n",
    "\n",
    "# Find accuracy by comparing predictions with y test data (correct answers)\n",
    "accuracy = accuracy_score(y_test, y_predictions)\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feeding the Forecast data to get next 14 days of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Try predicting the forecast and check to see if it matches up with the data from \n",
    "# the official source (Weather API)\n",
    "forecast_predictions = knn.predict(x_forecast)\n",
    "\n",
    "# See values next to eachother in print (1 = expected to rain)\n",
    "print(forecast_predictions)\n",
    "print(y_forecast.values.ravel(), end='\\n\\n\\n')\n",
    "\n",
    "forecast_accuracy = accuracy_score(y_forecast, forecast_predictions)\n",
    "\n",
    "print(f'Accuracy: {forecast_accuracy * 100:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
